{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X705N3oxe2rA"
      },
      "source": [
        "Mallikarjun edara\n",
        "#import required libraries\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D #layers in neural network\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re  #regular expression operations\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIsYaw-UgOZd",
        "outputId": "fef5f2ea-4d7d-4c12-c221-60fb4c430cc7"
      },
      "source": [
        "#Loading the sentiment dataset\n",
        "data = pd.read_csv('Sentiment.csv')\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','sentiment']]\n",
        "type(data)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOKAMhN1pTAO"
      },
      "source": [
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))#only keeping a-z,A-Z,0-9 in the data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX-f3klIpWTL"
      },
      "source": [
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')#removing retweets"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7bbYzJWpZmD"
      },
      "source": [
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')#tokenizing the sentence\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "\n",
        "X = pad_sequences(X)#padding the feature matrix - add zeros for matching length"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAzNlbhPpcOW",
        "outputId": "f60ae423-3eb1-4a07-c8e1-c2a386fc5690"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13871, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhED9PbJpe0U"
      },
      "source": [
        "def createmodel():\n",
        "    embed_dim=128 #dimension of the embedded layer\n",
        "    lstm_out=196 #LSTM layer neurons\n",
        "    model = Sequential()#Sequential neural network\n",
        "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "    return model\n",
        "    #print(model.summary)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOqv0vlvpisV"
      },
      "source": [
        "labelencoder = LabelEncoder()#conversion of categorical to Numerical\n",
        "#fitting the model\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
        "y = to_categorical(integer_encoded)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvvX2C40pmoK",
        "outputId": "3888f441-fed4-4daf-e81f-1840ca5a1367"
      },
      "source": [
        "print(data['sentiment'])\n",
        "print(integer_encoded)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0         Neutral\n",
            "1        Positive\n",
            "2         Neutral\n",
            "3        Positive\n",
            "4        Positive\n",
            "           ...   \n",
            "13866    Negative\n",
            "13867    Positive\n",
            "13868    Positive\n",
            "13869    Negative\n",
            "13870    Positive\n",
            "Name: sentiment, Length: 13871, dtype: object\n",
            "[1 2 1 ... 2 0 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwXsXPjdpn5e",
        "outputId": "2987cd35-407d-4ed8-80ce-013276a7a669"
      },
      "source": [
        "# train model\n",
        "batch_size = 32\n",
        "model = createmodel()\n",
        "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2)#more messages for higher verbose\n",
        "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size)\n",
        "print(score)\n",
        "print(acc)\n",
        "print(model.metrics_names)#model metrics"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "291/291 - 32s - loss: 0.8266 - accuracy: 0.6459\n",
            "144/144 - 2s - loss: 0.7956 - accuracy: 0.6549\n",
            "0.7955935597419739\n",
            "0.6548711061477661\n",
            "['loss', 'accuracy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKEXZC4ZWXP3"
      },
      "source": [
        "#1.Save the model and use the saved model to predict on new text data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "381Wdl7Fp9uE"
      },
      "source": [
        "model.save(\"model.h5\")#saving the model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7eWscLCqh1X"
      },
      "source": [
        "from keras.models import load_model #importing the package to get the saved model\n",
        "model_save= load_model(\"model.h5\")  #loading the model which is saved"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQKCmJ34q8mR",
        "outputId": "94366712-d1b5-4047-b0d8-a9bc68f0ad48"
      },
      "source": [
        "import numpy as np\n",
        "#processing the input text\n",
        "tweet = ['A lot of good things are happening.We are respected again throughout the world, and that is a great thing']\n",
        "tweet = tweet[0].lower()\n",
        "tweet = re.sub('[^a-zA-z0-9\\s]','',tweet)\n",
        "tweet = tokenizer.texts_to_sequences(tweet)#tokenizing the sentence\n",
        "tweet = pad_sequences(tweet, maxlen=28, dtype='int32', value=0)#padding - add zeros to match the sentence length\n",
        "#Standard analyzer defines up to three basic polar emotions (positions, negative, neutral)\n",
        "sentiment = model_save.predict_classes(tweet,batch_size=1, verbose=2)[0] #predicting the sentence text\n",
        "if sentiment == 0:\n",
        "    print(\"negative\")\n",
        "elif sentiment==1:\n",
        "    print(\"neutral\")\n",
        "else:\n",
        "    print(\"positive\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "103/103 - 1s\n",
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLIG9ku5W0Rm"
      },
      "source": [
        "#2.Applying gridsearchCV on the source code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1fLe3gJqxca",
        "outputId": "be242f64-913d-4551-dc8e-b02854a83634"
      },
      "source": [
        "#importing the required libraries\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# applying GridSearchCV on model\n",
        "model = KerasClassifier(build_fn=createmodel,verbose=2)#applying multiple hyper parameters for model initiation\n",
        "#hyper parameters\n",
        "batch_size= [40, 50, 60]\n",
        "epochs = [1, 2, 3]\n",
        "param_grid= dict(batch_size=batch_size, epochs=epochs) #creating dictionary for batch size and no of epochs\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid) #applying dictionary with hyper parameters for GridSearchCV\n",
        "grid_result=grid.fit(X_train,y = Y_train)#fitting the model\n",
        "#summary\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "186/186 - 23s - loss: 0.8445 - accuracy: 0.6367\n",
            "47/47 - 1s - loss: 0.7590 - accuracy: 0.6530\n",
            "186/186 - 22s - loss: 0.8467 - accuracy: 0.6367\n",
            "47/47 - 1s - loss: 0.7730 - accuracy: 0.6659\n",
            "186/186 - 23s - loss: 0.8493 - accuracy: 0.6322\n",
            "47/47 - 1s - loss: 0.8223 - accuracy: 0.6611\n",
            "186/186 - 23s - loss: 0.8425 - accuracy: 0.6334\n",
            "47/47 - 1s - loss: 0.8151 - accuracy: 0.6663\n",
            "186/186 - 22s - loss: 0.8438 - accuracy: 0.6403\n",
            "47/47 - 1s - loss: 0.7933 - accuracy: 0.6738\n",
            "Epoch 1/2\n",
            "186/186 - 23s - loss: 0.8475 - accuracy: 0.6349\n",
            "Epoch 2/2\n",
            "186/186 - 20s - loss: 0.6969 - accuracy: 0.7043\n",
            "47/47 - 1s - loss: 0.7336 - accuracy: 0.6799\n",
            "Epoch 1/2\n",
            "186/186 - 22s - loss: 0.8415 - accuracy: 0.6400\n",
            "Epoch 2/2\n",
            "186/186 - 21s - loss: 0.7024 - accuracy: 0.7030\n",
            "47/47 - 1s - loss: 0.7296 - accuracy: 0.6832\n",
            "Epoch 1/2\n",
            "186/186 - 23s - loss: 0.8485 - accuracy: 0.6365\n",
            "Epoch 2/2\n",
            "186/186 - 20s - loss: 0.6855 - accuracy: 0.7061\n",
            "47/47 - 1s - loss: 0.7483 - accuracy: 0.6880\n",
            "Epoch 1/2\n",
            "186/186 - 22s - loss: 0.8566 - accuracy: 0.6261\n",
            "Epoch 2/2\n",
            "186/186 - 20s - loss: 0.6975 - accuracy: 0.7017\n",
            "47/47 - 1s - loss: 0.7556 - accuracy: 0.6620\n",
            "Epoch 1/2\n",
            "186/186 - 23s - loss: 0.8507 - accuracy: 0.6374\n",
            "Epoch 2/2\n",
            "186/186 - 21s - loss: 0.6721 - accuracy: 0.7166\n",
            "47/47 - 1s - loss: 0.7869 - accuracy: 0.6695\n",
            "Epoch 1/3\n",
            "186/186 - 23s - loss: 0.8434 - accuracy: 0.6368\n",
            "Epoch 2/3\n",
            "186/186 - 21s - loss: 0.6882 - accuracy: 0.7035\n",
            "Epoch 3/3\n",
            "186/186 - 21s - loss: 0.6172 - accuracy: 0.7436\n",
            "47/47 - 1s - loss: 0.7594 - accuracy: 0.6832\n",
            "Epoch 1/3\n",
            "186/186 - 23s - loss: 0.8420 - accuracy: 0.6355\n",
            "Epoch 2/3\n",
            "186/186 - 20s - loss: 0.6919 - accuracy: 0.7033\n",
            "Epoch 3/3\n",
            "186/186 - 20s - loss: 0.6123 - accuracy: 0.7408\n",
            "47/47 - 1s - loss: 0.7442 - accuracy: 0.6880\n",
            "Epoch 1/3\n",
            "186/186 - 23s - loss: 0.8534 - accuracy: 0.6338\n",
            "Epoch 2/3\n",
            "186/186 - 20s - loss: 0.6821 - accuracy: 0.7115\n",
            "Epoch 3/3\n",
            "186/186 - 20s - loss: 0.6077 - accuracy: 0.7448\n",
            "47/47 - 1s - loss: 0.7856 - accuracy: 0.6907\n",
            "Epoch 1/3\n",
            "186/186 - 23s - loss: 0.8518 - accuracy: 0.6352\n",
            "Epoch 2/3\n",
            "186/186 - 20s - loss: 0.6868 - accuracy: 0.7064\n",
            "Epoch 3/3\n",
            "186/186 - 21s - loss: 0.6138 - accuracy: 0.7368\n",
            "47/47 - 1s - loss: 0.7625 - accuracy: 0.6744\n",
            "Epoch 1/3\n",
            "186/186 - 23s - loss: 0.8465 - accuracy: 0.6339\n",
            "Epoch 2/3\n",
            "186/186 - 21s - loss: 0.6821 - accuracy: 0.7056\n",
            "Epoch 3/3\n",
            "186/186 - 21s - loss: 0.6075 - accuracy: 0.7453\n",
            "47/47 - 1s - loss: 0.8045 - accuracy: 0.6598\n",
            "149/149 - 20s - loss: 0.8622 - accuracy: 0.6328\n",
            "38/38 - 1s - loss: 0.7622 - accuracy: 0.6622\n",
            "149/149 - 20s - loss: 0.8539 - accuracy: 0.6340\n",
            "38/38 - 1s - loss: 0.7942 - accuracy: 0.6482\n",
            "149/149 - 20s - loss: 0.8646 - accuracy: 0.6273\n",
            "38/38 - 1s - loss: 0.7784 - accuracy: 0.6665\n",
            "149/149 - 20s - loss: 0.8621 - accuracy: 0.6257\n",
            "38/38 - 1s - loss: 0.7525 - accuracy: 0.6798\n",
            "149/149 - 20s - loss: 0.8470 - accuracy: 0.6327\n",
            "38/38 - 1s - loss: 0.7769 - accuracy: 0.6674\n",
            "Epoch 1/2\n",
            "149/149 - 20s - loss: 0.8574 - accuracy: 0.6317\n",
            "Epoch 2/2\n",
            "149/149 - 18s - loss: 0.7008 - accuracy: 0.7000\n",
            "38/38 - 1s - loss: 0.7378 - accuracy: 0.6842\n",
            "Epoch 1/2\n",
            "149/149 - 20s - loss: 0.8451 - accuracy: 0.6375\n",
            "Epoch 2/2\n",
            "149/149 - 18s - loss: 0.6986 - accuracy: 0.7043\n",
            "38/38 - 1s - loss: 0.7577 - accuracy: 0.6826\n",
            "Epoch 1/2\n",
            "149/149 - 20s - loss: 0.8678 - accuracy: 0.6278\n",
            "Epoch 2/2\n",
            "149/149 - 18s - loss: 0.7009 - accuracy: 0.7018\n",
            "38/38 - 1s - loss: 0.7418 - accuracy: 0.6896\n",
            "Epoch 1/2\n",
            "149/149 - 21s - loss: 0.8548 - accuracy: 0.6297\n",
            "Epoch 2/2\n",
            "149/149 - 18s - loss: 0.6936 - accuracy: 0.7011\n",
            "38/38 - 1s - loss: 0.7358 - accuracy: 0.6787\n",
            "Epoch 1/2\n",
            "149/149 - 20s - loss: 0.8504 - accuracy: 0.6315\n",
            "Epoch 2/2\n",
            "149/149 - 18s - loss: 0.6912 - accuracy: 0.7026\n",
            "38/38 - 1s - loss: 0.7677 - accuracy: 0.6695\n",
            "Epoch 1/3\n",
            "149/149 - 21s - loss: 0.8515 - accuracy: 0.6316\n",
            "Epoch 2/3\n",
            "149/149 - 18s - loss: 0.6970 - accuracy: 0.7014\n",
            "Epoch 3/3\n",
            "149/149 - 18s - loss: 0.6197 - accuracy: 0.7384\n",
            "38/38 - 1s - loss: 0.7404 - accuracy: 0.6665\n",
            "Epoch 1/3\n",
            "149/149 - 20s - loss: 0.8603 - accuracy: 0.6329\n",
            "Epoch 2/3\n",
            "149/149 - 18s - loss: 0.7054 - accuracy: 0.7003\n",
            "Epoch 3/3\n",
            "149/149 - 18s - loss: 0.6238 - accuracy: 0.7386\n",
            "38/38 - 1s - loss: 0.7384 - accuracy: 0.6767\n",
            "Epoch 1/3\n",
            "149/149 - 20s - loss: 0.8536 - accuracy: 0.6357\n",
            "Epoch 2/3\n",
            "149/149 - 18s - loss: 0.6879 - accuracy: 0.7082\n",
            "Epoch 3/3\n",
            "149/149 - 18s - loss: 0.6062 - accuracy: 0.7432\n",
            "38/38 - 1s - loss: 0.8062 - accuracy: 0.6902\n",
            "Epoch 1/3\n",
            "149/149 - 20s - loss: 0.8498 - accuracy: 0.6360\n",
            "Epoch 2/3\n",
            "149/149 - 18s - loss: 0.6937 - accuracy: 0.7065\n",
            "Epoch 3/3\n",
            "149/149 - 18s - loss: 0.6060 - accuracy: 0.7471\n",
            "38/38 - 1s - loss: 0.7597 - accuracy: 0.6588\n",
            "Epoch 1/3\n",
            "149/149 - 20s - loss: 0.8506 - accuracy: 0.6332\n",
            "Epoch 2/3\n",
            "149/149 - 17s - loss: 0.6836 - accuracy: 0.7081\n",
            "Epoch 3/3\n",
            "149/149 - 18s - loss: 0.6045 - accuracy: 0.7488\n",
            "38/38 - 1s - loss: 0.8058 - accuracy: 0.6593\n",
            "124/124 - 18s - loss: 0.8611 - accuracy: 0.6314\n",
            "31/31 - 1s - loss: 0.7568 - accuracy: 0.6568\n",
            "124/124 - 18s - loss: 0.8543 - accuracy: 0.6302\n",
            "31/31 - 1s - loss: 0.7787 - accuracy: 0.6616\n",
            "124/124 - 18s - loss: 0.8560 - accuracy: 0.6289\n",
            "31/31 - 1s - loss: 0.7796 - accuracy: 0.6665\n",
            "124/124 - 18s - loss: 0.8603 - accuracy: 0.6265\n",
            "31/31 - 1s - loss: 0.7729 - accuracy: 0.6760\n",
            "124/124 - 18s - loss: 0.8495 - accuracy: 0.6339\n",
            "31/31 - 1s - loss: 0.7840 - accuracy: 0.6679\n",
            "Epoch 1/2\n",
            "124/124 - 18s - loss: 0.8588 - accuracy: 0.6329\n",
            "Epoch 2/2\n",
            "124/124 - 16s - loss: 0.6956 - accuracy: 0.7041\n",
            "31/31 - 1s - loss: 0.7264 - accuracy: 0.6810\n",
            "Epoch 1/2\n",
            "124/124 - 18s - loss: 0.8573 - accuracy: 0.6312\n",
            "Epoch 2/2\n",
            "124/124 - 16s - loss: 0.6921 - accuracy: 0.7074\n",
            "31/31 - 1s - loss: 0.7470 - accuracy: 0.6778\n",
            "Epoch 1/2\n",
            "124/124 - 18s - loss: 0.8639 - accuracy: 0.6310\n",
            "Epoch 2/2\n",
            "124/124 - 16s - loss: 0.7051 - accuracy: 0.6996\n",
            "31/31 - 1s - loss: 0.7440 - accuracy: 0.6794\n",
            "Epoch 1/2\n",
            "124/124 - 18s - loss: 0.8894 - accuracy: 0.6207\n",
            "Epoch 2/2\n",
            "124/124 - 16s - loss: 0.7089 - accuracy: 0.6929\n",
            "31/31 - 1s - loss: 0.7441 - accuracy: 0.6900\n",
            "Epoch 1/2\n",
            "124/124 - 18s - loss: 0.8640 - accuracy: 0.6282\n",
            "Epoch 2/2\n",
            "124/124 - 16s - loss: 0.6951 - accuracy: 0.7033\n",
            "31/31 - 1s - loss: 0.7714 - accuracy: 0.6803\n",
            "Epoch 1/3\n",
            "124/124 - 18s - loss: 0.8571 - accuracy: 0.6312\n",
            "Epoch 2/3\n",
            "124/124 - 16s - loss: 0.7082 - accuracy: 0.6975\n",
            "Epoch 3/3\n",
            "124/124 - 16s - loss: 0.6183 - accuracy: 0.7380\n",
            "31/31 - 1s - loss: 0.7581 - accuracy: 0.6762\n",
            "Epoch 1/3\n",
            "124/124 - 19s - loss: 0.8551 - accuracy: 0.6342\n",
            "Epoch 2/3\n",
            "124/124 - 16s - loss: 0.6912 - accuracy: 0.7026\n",
            "Epoch 3/3\n",
            "124/124 - 16s - loss: 0.6187 - accuracy: 0.7424\n",
            "31/31 - 1s - loss: 0.7490 - accuracy: 0.6837\n",
            "Epoch 1/3\n",
            "124/124 - 18s - loss: 0.8555 - accuracy: 0.6273\n",
            "Epoch 2/3\n",
            "124/124 - 16s - loss: 0.6900 - accuracy: 0.7070\n",
            "Epoch 3/3\n",
            "124/124 - 16s - loss: 0.6137 - accuracy: 0.7435\n",
            "31/31 - 1s - loss: 0.7647 - accuracy: 0.6821\n",
            "Epoch 1/3\n",
            "124/124 - 18s - loss: 0.8730 - accuracy: 0.6247\n",
            "Epoch 2/3\n",
            "124/124 - 16s - loss: 0.7023 - accuracy: 0.7006\n",
            "Epoch 3/3\n",
            "124/124 - 16s - loss: 0.6170 - accuracy: 0.7364\n",
            "31/31 - 1s - loss: 0.7487 - accuracy: 0.6814\n",
            "Epoch 1/3\n",
            "124/124 - 18s - loss: 0.8440 - accuracy: 0.6355\n",
            "Epoch 2/3\n",
            "124/124 - 16s - loss: 0.6758 - accuracy: 0.7123\n",
            "Epoch 3/3\n",
            "124/124 - 16s - loss: 0.6032 - accuracy: 0.7463\n",
            "31/31 - 1s - loss: 0.7849 - accuracy: 0.6808\n",
            "Epoch 1/2\n",
            "155/155 - 22s - loss: 0.8489 - accuracy: 0.6342\n",
            "Epoch 2/2\n",
            "155/155 - 20s - loss: 0.6805 - accuracy: 0.7097\n",
            "Best: 0.681697 using {'batch_size': 60, 'epochs': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
